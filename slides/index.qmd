---
title: "A Practical Introduction to Bayesian Modelling with `{greta}`"
subtitle: "Bayes on the Beach<br>2026-02-09"
author: "Nicholas Tierney"
institute: "Statistical Consultant<br>nipaluna, lutruwita (Hobart, Tasmania)"
format:
  revealjs:
    theme: [blood, extra.scss]
    incremental: true
    slide-number: c
    show-slide-number: all
    footer: "njtierney.github.io/talk-botb26"
editor: visual
execute:
  echo: true
  warning: false
  cache: true
  freeze: true
---

```{r}
#| label: library
#| include: false
library(tidyverse)
library(knitr)
library(colorspace)
library(naniar)
library(visdat)
library(icons)
library(naniar)
library(tidyverse)
library(ggrain)
library(tinytable)
library(greta)
greta_sitrep()
```

```{r}
#| label: source-r-files
#| echo: false
#| message: false
#| output: false
lapply(list.files(here::here("R"), full.names = TRUE), source)
```

```{r}
#| label: helpers
#| include: false

icons_fa <- icons::fontawesome
icon_box <- icon_style(icons_fa$solid$`box-open`, fill = "#f0a800")
icon_link <- icon_style(icons_fa$solid$link, fill = "#f0a800")
icon_twitter <- icon_style(icons_fa$brands$twitter, fill = "#f0a800")
icon_github <- icon_style(icons_fa$brands$github, fill = "#f0a800")
icon_plane <- icon_style(icons_fa$solid$`paper-plane`, fill = "#f0a800")


as_table <- function(...) knitr::kable(..., format='html', digits = 3)

theme_set(
  theme_grey(base_size = 16) +
  theme(
    legend.position = "bottom",
    plot.background = element_rect(fill = "transparent"),
    legend.background = element_rect(fill = "transparent")
  )
)

```

## Who am I? The story so far

-   **2008-2012**: Undergrad + honours in Psychology \@ UQ

-   **2013-2017**: PhD Statistics \@ QUT
    -   EDA / Bayesian / Geospatial / Optimal placement

-   **2017 - 2020**: Research Fellow / Lecturer \@ Monash

    -   Design EDA R packages: [`visdat`](), [`naniar`](), [`brolgar`]()

-   **2021 - 2025**: **Research Software Engineer** \@ The Kids

    -   Maintain and design R packages: [`greta`](), [`conmat`]()

-   **2025 - **: Statistical Consultant

    -   Statistical modelling, software, teaching, code review
    
:::{.notes}
-   Maintain Statistical Software (like greta)

-   Translate econometric models from code --> R package

-   Extend epidemiological modelling software

-   Provide code review to researchers

-   Translate Models of urban biodiversity --> R packages

-   Develop colour palettes, ggplot themes, automation

:::
    

# ❤️ Hiking! `njt.micro.blog`

![](images/pct-collage.jpg){background-size="75%"}

<!-- ##  {background-image="img/pct-collage.jpg" background-size="75%"} -->

##  {background-image="images/greta-logo-background.png" background-size="contain"}

##  {background-image="images/idem-lab.png" background-size="contain"}

## Designing modelling interfaces is (NP) hard

:::: columns

::: {.column width="60%"}

Nick Golding (right) created {greta} in 2016, to express statistical models in R, while taking advantage of Google `Tensorflow`:

  -  automatic differentiation
  -  efficient linear algebra
  -  highly parallel
  -  new samplers (SNAPER-HMC)

:::

::: {.column width="40%"}

![](images/nick-golding.jpeg){width="80%"}

:::

::::


---


## A penguins model {.smaller}

:::: {.columns}
::: {.column width="40%"}
$$
\begin{aligned}
\beta_0, \beta_1, \beta_2 &\sim \text{Normal}(0, 10) \\
\eta_i &= \beta_0 + \\
&\beta_1 \cdot \text{flipper}_i + \\
&\beta_2 \cdot \text{mass}_i \\
\text{logit}(p_i) &= \eta_i \\
y_i &\sim \text{Bernoulli}(p_i), \\
i &= 1, \ldots, N
\end{aligned}
$$
:::

::: {.column width="60%"}
::: {.panel-tabset}

## JAGS

```{r}
#| eval: false
model {
  # Priors
  # precision = 1/variance = 1/100
  intercept ~ dnorm(0, 0.001)  
  coef_flipper ~ dnorm(0, 0.001)
  coef_mass ~ dnorm(0, 0.001)
  
  # Likelihood
  for(i in 1:N) {
    logit(probability_female[i]) <- intercept + 
          coef_flipper * flipper_length_mm[i] +
          coef_mass * body_mass_g[i]
    y[i] ~ dbern(probability_female[i])
  }
}
```

## STAN

```r
data {
  int<lower=0> N;
  vector[N] flipper_length_mm;
  vector[N] body_mass_g;
  array[N] int<lower=0,upper=1> y;
}
parameters {
  real intercept;
  real coef_flipper;
  real coef_mass;
}
model {
  // Priors
  intercept ~ normal(0, 10);
  coef_flipper ~ normal(0, 10);
  coef_mass ~ normal(0, 10);
  
  // Likelihood (vectorized)
  y ~ bernoulli_logit(intercept + 
                      coef_flipper * flipper_length_mm +
                      coef_mass * body_mass_g);
}
```

## greta

```{r}
#| eval: false
# Priors
intercept <- normal(0, 10)
coef_flipper <- normal(0, 10)
coef_mass <- normal(0, 10)

# Linear predictor
eta <- intercept + 
  coef_flipper * flipper_length_mm + 
  coef_mass * body_mass_g

# Link function
probability_female <- ilogit(eta)

# Likelihood
y <- as_data(is_female_numeric)
distribution(y) <- bernoulli(probability_female)
m <- model(intercept, coef_flipper, coef_mass)
```

:::

:::
::::


# {background-image="images/greta-vs-stan-jags.png" background-size="65%"}


## Default: Gradient-based inference

```{r}
#| label: gradient-based
#| echo: false
include_graphics("images/gradient-based.png")
```

## Using `greta`

:::{.panel-tabset}

## Model prep

```{r}
#| label: run-greta-model
#| eval: false
# Priors
intercept <- normal(0, 10)
coef_flipper <- normal(0, 10)
coef_mass <- normal(0, 10)

# Linear predictor
eta <- intercept + 
  coef_flipper * flipper_length_mm + 
  coef_mass * body_mass_g

# Link function
probability_female <- ilogit(eta)

# Likelihood
y <- as_data(is_female_numeric)
distribution(y) <- bernoulli(probability_female)
m <- model(p, theta)
```

## Samplers

```{r}
#| eval: false
draws_hmc <- mcmc(m, sampler = hmc()) # default
draws_rwmh <- mcmc(m, sampler = rwmh())
draws_slice <- mcmc(m, sampler = slice())
```

## Other options

```{r}
#| eval: false
draws <- mcmc(m,
              n_samples = 1000,
              thin = 10,
              warmup = 1000,
              chains = 16,
              n_cores = 6,
              initial_values = initials(
                p = 0,
                theta = 100
              )
              )
```

:::

## {greta} integrattions

```{r}
#| label: run-model
#| echo: false
library(palmerpenguins)
library(tidyverse)
library(bayesplot)

penguins_for_modelling <- penguins |>
  # remove missing value records
  drop_na() |>
  # rescale the length and mass variables to make the coefficient priors easier
  # to define
  mutate(
    across(
      c(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g),
      .fns = list(scaled = \(x) scale(x))
    ),
    # code the sex as per a Bernoulli distribution
    is_female_numeric = if_else(sex == "female", 1, 0),
    .after = island
  )

library(greta)

# define priors
intercept <- normal(0, 10)
coef_flipper_length <- normal(0, 10)
coef_body_mass <- normal(0, 10)

# define linear predictor
eta <- intercept +
  coef_flipper_length * penguins_for_modelling$flipper_length_mm_scaled +
  coef_body_mass * penguins_for_modelling$body_mass_g_scaled

# apply link function
probability_female <- ilogit(eta)

# define likelihood
y <- as_data(penguins_for_modelling$is_female_numeric)
distribution(y) <- bernoulli(probability_female)

# combine into a model object
m <- model(intercept, coef_flipper_length, coef_body_mass)
# do MCMC - 4 chains, 1000 on each after 1000 warmuup (default is 2 chains)
draws <- mcmc(
  m,
  sampler = hmc(),
  n_samples = 1000,
  warmup = 1000,
  chains = 4,
  n_cores = 3
)
```


::: {.panel-tabset}

## summary

```{r}
summary(draws)
```


## coda

```{r}
#| fig-height: 4
plot(draws)
```

## traceplot

```{r}
#| fig-height: 4
bayesplot::mcmc_trace(draws)
```

## density

```{r}
#| fig-height: 4
bayesplot::mcmc_dens(draws)
```

## diagnostics 

```{r}
coda::gelman.diag(draws, autoburnin = FALSE, multivariate = FALSE)
```

:::

## {greta} is Extendable

```{r}
#| label: extendable2
#| echo: false
include_graphics("images/greta-extendable.png")
```

# `greta.gam`

:::{.columns}

:::{.column width="45%"}

> Use [mgcv](https://CRAN.R-project.org/package=mgcv)
smoother functions and formula syntax to define smooth terms for use in
a [greta](https://greta-stats.org/) model. Define your
likelihood, fit with MCMC.

:::

:::{.column width="55%"}

```{r}
#| echo: false
#| include: false
library(mgcv)
set.seed(2024 - 12 - 12)
# simulate some data...
dat <- gamSim(1, n = 400, dist = "normal", scale = 0.3)
```

```{r}
mgcv_fit <- gam(y ~ s(x2), 
                data = dat)
plot(mgcv_fit, 
     scheme = 1, 
     shift = coef(mgcv_fit)[1])
```

:::

:::

## `greta.gam`

:::{.panel-tabset}

## code

``` r
linear_predictor <- smooths(~ s(x2), data = dat)

dist_sd <- cauchy(0, 1, truncation = c(0, Inf))
distribution(dat$y) <- normal(mean = linear_predictor, sd = dist_sd)

pred_dat <- data.frame(x2 = seq(0, 1, length.out = 100))

linear_preds <- evaluate_smooths(linear_predictor, newdata = pred_dat)

m <- model(linear_preds)

draws <- mcmc(m, n_samples = 200, verbose = FALSE)

apply(draws[[1]], 1, lines, x = pred_dat$x2, 
      col = adjustcolor("firebrick", alpha.f = 0.1))
points(dat$x2, dat$y, pch = 19, cex = 0.2)
```

## plot

![](images/greta-gam-mcmc.png)


:::

## Future Features

- Marginalisation (discrete, laplace, variational)
- Discrete Samplers
- Samplers for big data
- HMC Snaper
- Extension packages (lme-like formula, more distributions, point processes)

## Why 'greta' ?

::::: columns
::: {.column width="60%"}
Grete Hermann (1901 - 1984)

wrote the first algorithms for computer algebra

... without a computer

(To avoid people saying 'greet', the package is spelled *greta* instead)
:::

::: {.column width="40%"}
```{r show-grete, out.width = "75%", echo = FALSE}
include_graphics("images/grete-hermann-smile.png")
```
:::
:::::

# Modelling Penguins with `palmerpenguins` {background-color="white"}

![](images/lter_penguins.png)

## Our Turn: Modelling Penguins! {.smaller}

:::{.columns}

:::{.column width="40%"}

![](images/palmerpenguins.png)

:::


:::{.column width="60%"}


* Build a model to predict the sex of an individual penguin based on measurements of that individual.
* This is a thing people do - see ["Ecological Sexual Dimorphism and Environmental Variability within a Community of Antarctic Penguins (Genus Pygoscelis)"](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081) by Gorman et al., 2014.
* The `penguins` dataset is now also in base R 4.5.0! (With slight differences, see [njtierney.com/post/2025/04/14/r-version-4-5-0-is-out/](https://www.njtierney.com/post/2025/04/14/r-version-4-5-0-is-out/))

:::

:::

## Our Turn: Modelling Penguins! {.smaller}

:::{.columns}

:::{.column width="50%"}

- Predict probability of a penguin being female, based on flipper length, and body mass.
- Demonstrate greta workflow: 
  - DAG plot
  - `calculate()` for simulations
  - integrates with `coda` and `bayesplot`

:::

:::{.column width="50%"}

$$
\begin{aligned}
\beta_0, \beta_1, \beta_2 &\sim \text{Normal}(0, 10) \\
\eta_i &= \beta_0 + \\
&\beta_1 \cdot \text{flipper}_i + \\
&\beta_2 \cdot \text{mass}_i \\
\text{logit}(p_i) &= \eta_i \\
y_i &\sim \text{Bernoulli}(p_i), \\
i &= 1, \ldots, N
\end{aligned}
$$

:::

:::

## Our turn: posit.cloud {.small}

```{r}
#| echo: false
cloud_link <- qrcode::qr_code("https://posit.cloud/spaces/749995/join?access_code=nwqtNUNzpeSkfAgWHbgUNiba_Hm4fuggJSQqhDU3")
plot(cloud_link)
```

* Sign in with a github/google
* Follow along with me
* Or run locally from [github.com/greta-dev/greta-botb26-workshop](https://github.com/greta-dev/greta-botb26-workshop)


## Resources 

::: {.nonincremental}
- **github:** [github.com/greta-dev/greta](https://github.com/greta-dev/greta)
- **Docs:** [greta-stats.org](https://greta-stats.org)
- **Help:** [https://forum.greta-stats.org/](https://forum.greta-stats.org/)

Install: (not currently on CRAN - soon to be amended!)

```{r}
#| eval: false
remotes::install_github("greta-dev/greta")
```

Or via the [r-universe](https://greta-dev.r-universe.dev/builds)

```{r}
#| eval: false
install.packages("greta", 
                 repos = c("https://greta-dev.r-universe.dev",
                           "https://cloud.r-project.org"))
```

:::



# Extras

# {background-image="images/standards.png" background-size="contain"}





## The WinBUGS example: Air {.smaller}

Air analyses reported respiratory illness versus exposure to nitrogen dioxide in 103 children. The parameters `alpha`, `beta` and `sigma2` are known in advance, and the data are grouped into three categories.



::::: columns
::: {.column width="40%"}
**Mathematical Model:**

$$
\begin{aligned}
\theta_1, \theta_2 &\sim \text{Normal}(0, 32) \\
\mu_j &= \alpha + \beta Z_j \\
X_j &\sim \text{Normal}(\mu_j, \sigma) \\
\text{logit}(p_j) &= \theta_1 + \theta_2 X_j \\
y_j &\sim \text{Binomial}(n_j, p_j) \\
j &= 1, \ldots, J \\
\end{aligned}
$$

:::

::: {.column width="60%"}
:::{.panel-tabset}

## Data

```{r}
y <- c(21, 20, 15)
n <- c(48, 34, 21)
Z <- c(10, 30, 50)
alpha <- 4.48
beta <- 0.76
sigma2 <- 81.14
sigma <- sqrt(sigma2)
tau <- 1 / sigma2
J <- 3
```


## JAGS

```{.bugs}
for(j in 1 : J) {
   y[j] ~ dbin(p[j], n[j])
   logit(p[j]) <- theta[1] + theta[2] * X[j]
   X[j] ~ dnorm(mu[j], tau)
   mu[j] <- alpha + beta * Z[j]
}
theta[1] ~ dnorm(0.0, 0.001)
theta[2] ~ dnorm(0.0, 0.001)
```

## STAN

:::{.small}
```{.stan}
data {
  real alpha;
  real beta;
  real<lower=0> sigma2;
  int<lower=0> J;
  array[J] int y;
  vector[J] Z;
  array[J] int n;
}
transformed data {
  real<lower=0> sigma;
  sigma = sqrt(sigma2);
}
parameters {
  real theta1;
  real theta2;
  vector[J] X;
}
model {
  array[J] real p;
  theta1 ~ normal(0, 32); // 32^2 = 1024 
  theta2 ~ normal(0, 32);
  X ~ normal(alpha + beta * Z, sigma);
  y ~ binomial_logit(n, theta1 + theta2 * X);
}
```
:::

## greta

```{r}
#| eval: false
theta <- normal(0, 32, dim = 2)
mu <- alpha + beta * Z
X <- normal(mu, sigma)
p <- ilogit(theta[1] + theta[2] * X)
distribution(y) <- binomial(n, p)
```
:::

:::
:::::
